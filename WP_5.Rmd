---
title: "WP_5"
author: "R.Spielhofer"
date: "20/10/2020"
output: html_document
---

Spatial "clustering" of optimal WT solutions from WP3

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
require(sf)
require(sp)
require(ggplot2)
require(DBI)
require(RPostgreSQL)
require(rpostgis)
require(ggpubr)
require(spatstat)
require(reticulate)
require(tidyr)
require(maptools)
require(RPostgres)
require(stringr)
require(car)
require(caret)
require(plyr)
```



## some statistics B3
```{r}
conn <- dbConnect(Postgres(), dbname = "publication_3_fin", host = "localhost", port = 5432, 
                      user = "postgres", password = "reto89LLSIMI")


B3<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_2020-10-21_res"))
B4<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B4_2020-10-10_res"))
B4_FFFmin<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B4_FFF-_2020-10-08_res"))

B3$sec_cat[B3$rel_nonDOM< .75] <- "low"
B3$sec_cat[B3$rel_nonDOM>=.75] <- "high"

# Convert the column to a factor
B3$sec_cat <- factor(B3$sec_cat)
B3<-st_drop_geometry(B3)
B3_sec<-subset(B3,B3$sec_cat=="high")

B4$sec_cat[B4$sum_pop_pareto< 75] <- "low"
B4$sec_cat[B4$sum_pop_pareto>=75] <- "high"

# Convert the column to a factor
B4$sec_cat <- factor(B4$sec_cat)
B4<-st_drop_geometry(B4)
B4_opt<-subset(B4,B4$sum_pop_pareto>75)
sum(B4_opt$prod_MW)

all<-rbind(B4_opt,B3_sec)
commonB3_B4<-all[duplicated(all$WT_ID), ]
sum(commonB3_B4$prod_MW)

commontmp<-rbind(commonB3_B4,B3_noBI)
commontmp<-all[duplicated(commontmp$WT_ID), ]





B3_inFOR<-subset(B3,B3$DIST_FOR<1)
B3_inFOR<-subset(B3_inFOR,B3_inFOR$rel_nonDOM>0.01)

B3_inFFF<-subset(B3,B3$FFF==1)
B3_inFFF<-subset(B3_inFFF,B3_inFFF$sum_pop_pareto>1)

B3_inISOS<-subset(B3,B3$DIST_ISOS<1000)
B3_inISOS<-subset(B3_inISOS,B3_inISOS$sum_pop_pareto>1)

B3_noBI<-subset(B3,B3$DIST_ISOS>1000&B3$FFF==0&B3$DIST_FOR>1)
B3_noBI<-subset(B3_noBI,B3_noBI$sum_pop_pareto>75)




B3_inFOR<-B3_inFOR[,c(18:23,26:30,35:36,44)]

mod_inFOR<-list()
for(i in 1:13){
    fmla <- formula(paste(names(B3_inFOR)[i], " ~ sec_cat"))
    mod_inFOR[[i]]<-wilcox.test(fmla, data = B3_inFOR, paired = FALSE)
}



B3_inISOS<-B3_inISOS[,c(18:23,26:30,35:36,44)]
mod_inISOS<-list()
for(i in 1:13){
    fmla <- formula(paste(names(B3_inISOS)[i], " ~ sec_cat"))
    mod_inISOS[[i]]<-wilcox.test(fmla, data = B3_inISOS, paired = FALSE)
}



B3_inFFF<-B3_inFFF[,c(18:23,26:30,35:36,44)]

mod_inFFF<-list()
for(i in 1:13){
    fmla <- formula(paste(names(B3_inFFF)[i], " ~ sec_cat"))
    mod_inFFF[[i]]<-wilcox.test(fmla, data = B3_inFFF, paired = FALSE)
}


B3_noBI<-B3_noBI[,c(18:23,26:30,35:36,44)]

mod_noBI<-list()
for(i in 1:13){
    fmla <- formula(paste(names(B3_noBI)[i], " ~ sec_cat"))
    mod_noBI[[i]]<-wilcox.test(fmla, data = B3_noBI, paired = FALSE)
}

B4<-st_drop_geometry(B4)
B4<-B4[,c(18:23,26:30,35:36,43)]

mod_B4<-list()
for(i in 1:13){
    fmla <- formula(paste(names(B4)[i], " ~ sec_cat"))
    mod_B4[[i]]<-wilcox.test(fmla, data = B4, paired = FALSE)
}
mod_B4


tapply(B3_noBI$DIST_BUILD,B3_noBI$sec_cat,mean)

mapview::mapview(commonB3_B4,zcol="sum_pop_pareto")


```


## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
conn <- dbConnect(Postgres(), dbname = "publication_3_fin", host = "localhost", port = 5432, 
                      user = "postgres", password = "reto89LLSIMI")


B3<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_2020-10-08_res"))
B3<-st_drop_geometry(B3)
B4<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B4_2020-10-10_res"))

B3_FFF<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_FFF+_2020-10-08_res"))
B3_FFF<-st_drop_geometry(B3_FFF)

B3_FOR<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_FOR+_2020-10-08_res"))
B3_FOR<-st_drop_geometry(B3_FOR)

B3_ISOS<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_ISOS+_2020-10-14_res"))
B3_ISOS<-st_drop_geometry(B3_ISOS)

B4<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B4_2020-10-10_res"))
B4<-st_drop_geometry(B4)

B_join<-join(B3,B3_FOR,by="WT_ID", type="left")
B_join<-B_join[,-c(43:82)]
names(B_join)[names(B_join) == "sum_pop_pareto.1"] <- "sum_popPAR_B3_FOR"

B_join<-join(B_join,B3_FFF,by="WT_ID", type="left")
B_join<-B_join[,-c(44:83)]
names(B_join)[names(B_join) == "sum_pop_pareto.1"] <- "sum_popPAR_B3_FFF"

B_join<-join(B_join,B3_ISOS,by="WT_ID", type="left")
B_join<-B_join[,-c(45:84)]
names(B_join)[names(B_join) == "sum_pop_pareto.1"] <- "sum_popPAR_B3_ISOS"

B_join<-join(B_join,B4,by="WT_ID", type="left")
B_join<-B_join[,-c(46:85)]
names(B_join)[names(B_join) == "sum_pop_pareto.1"] <- "sum_popPAR_B4"



DAT_MOD<-B_join
DAT_MOD <- DAT_MOD %>%
  mutate(sum_pop_pareto = sum_pop_pareto > 0)

DAT_MOD <- DAT_MOD %>%
  mutate(sum_popPAR_B3_FFF= sum_popPAR_B3_FFF>0)
DAT_MOD[c("sum_popPAR_B3_FFF")][is.na(DAT_MOD[c("sum_popPAR_B3_FFF")])] <- FALSE

DAT_MOD <- DAT_MOD %>%
  mutate(sum_popPAR_B3_FOR= sum_popPAR_B3_FOR>0)
DAT_MOD[c("sum_popPAR_B3_FOR")][is.na(DAT_MOD[c("sum_popPAR_B3_FOR")])] <- FALSE

DAT_MOD <- DAT_MOD %>%
  mutate(sum_popPAR_B3_ISOS= sum_popPAR_B3_ISOS>0)
DAT_MOD[c("sum_popPAR_B3_ISOS")][is.na(DAT_MOD[c("sum_popPAR_B3_ISOS")])] <- FALSE

DAT_MOD <- DAT_MOD %>%
  mutate(sum_popPAR_B4= sum_popPAR_B4>0)
DAT_MOD[c("sum_popPAR_B4")][is.na(DAT_MOD[c("sum_popPAR_B4")])]<- FALSE

```

```{r}
##---------------split sample according to step 2 of prestudy into train and test data sample-----------------
#with the createDataPartition function it preserves the proportion of y (CHOICE in this case)!

#standardize data
preProcess_range_model <- preProcess(DAT_MOD[,c(5:15,18:23,25:30,32,34,35,42:46)], method='range')
preProcess_range_model <- preProcess(DAT_MOD[,c(5:15,18:23,25:30,32,34,35,42:46)], 
                        method = c("center", "scale", "nzv"))
preProcess_range_model$method



PRED <- predict(preProcess_range_model, newdata = DAT_MOD[,c(5:15,18:23,25:30,32,34,35,42:46)])


# Step 1: Get row numbers for the training data
trainRowNumbers <- createDataPartition(PRED$sum_pop_pareto, p=0.7, list=FALSE)
# Step 2: Create the training  dataset
trainset <- PRED[trainRowNumbers,]
# Step 3: Create the test dataset
testset <- PRED[-trainRowNumbers,]

outcomeName <- variable.names(PRED[27])
pred_names<-variable.names(PRED[,c(1:26)])
```


```{r}
# Define the train control
fitControl <- trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = T,   verboseIter = FALSE)

```

```{r}


##----------RF tune
mtry <- sqrt(ncol(trainset[,pred_names]))
RFtune <- expand.grid(mtry=mtry)
#simple
start<-Sys.time()
#rf_mod<-train(trainset[,pred_names],  as.factor(trainset[,outcomeName]), method = "rf")
rf_B3<-train(trainset[,pred_names],  as.factor(trainset[,outcomeName]), method = "rf",trControl = fitControl,tunegrid=RFtune)
end<-Sys.time()
end-start




varimp_B3 <- varImp(rf_mod)
VARIMP_B3<-varimp_B3$importance
write.csv(VARIMP_B3,"C:/Users/spreto/Desktop/B3.csv")

varimp_FFF <- varImp(rf_FFF)
VARIMP_FFF<-varimp_FFF$importance
write.csv(VARIMP_FFF,"C:/Users/spreto/Desktop/FFF.csv")

varimp_FOR <- varImp(rf_FOR)
VARIMP_FOR<-varimp_FOR$importance
write.csv(VARIMP_FOR,"C:/Users/spreto/Desktop/FOR.csv")

varimp_ISOS <- varImp(rf_ISOS)
VARIMP_ISOS<-varimp_ISOS$importance

write.csv(VARIMP_ISOS,"C:/Users/spreto/Desktop/ISOS.csv")


varimp_B4 <- varImp(rf_mod)
VARIMP_B4<-varimp_B4$importance

write.csv(VARIMP_B4,"C:/Users/spreto/Desktop/B4.csv")

plot(varimp_rf, main="Variable Importance with RF")
#predict RF
pred_rf<-predict(rf_B3, testset)
#conf matrix
confusionMatrix(pred_rf, as.factor(testset$sum_pop_pareto))

RMSE(pred_rf,testset$sum_pop_pareto)
densityplot(rf_mod)
testset$pred<-pred_rf
xyplot(testset$pred,testset$sum_pop_pareto)

```


```{r}
GLMMOD_ISOS<-train(trainset[,pred_names],  as.factor(trainset[,outcomeName]), method = "glm",family="binomial",trControl= fitControl)
imp_isosGLM<-varImp(GLMMOD_ISOS)
plot(imp_isosGLM)


```

```{r}
require(ggsci)
my_comparisons <- list( c("TRUE", "FALSE"))
ggboxplot(DAT_MOD, x = "sum_popPAR_B3_FFF", y = "ALTI", 
        ylab = "n_WT", xlab = "SCENARIO")+
  stat_compare_means(comparisons = my_comparisons, label = "p.signif", 
                     method = "t.test" )

```

