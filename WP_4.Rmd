<<<<<<< HEAD
---
title: "Results and PLOTS wind optim project"
author: "R.Spielhofer"
date: "22 June 2020"
output: html_document
---

```{r setup, include=FALSE}

require(raster)
require(rgdal)
require(dplyr)
require(sf)
require(sp)
require(ggplot2)
require(tmap)
require(tmaptools)
require(DBI)
require(RPostgreSQL)
require(rpostgis)
require(ggpubr)
require(spatstat)
require(rstatix)
require(reticulate)
require(tidyr)
require(maptools)
require(RPostgres)
require(stringr)
require(car)
library(onewaytests)
library(psych)
library(plot3D)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

#Load data

```{r}
cur_dat<-Sys.Date()
pareto<-read.csv("Y:/people/spreto/2001_WIND_OPTIM/par_fitness_all_201130.csv", sep=",")
#pareto<-subset(pareto,pareto$MODEL_RUN==201201)
# restrictive scen
tmp_dat<-subset(pareto, pareto$SCENARIO=="B3"|pareto$SCENARIO=="B3_FOR+"|pareto$SCENARIO=="B3_ISOS+"|pareto$SCENARIO=="B3_CRF+")

#relaxing scen
tmp_dat<-subset(pareto, pareto$SCENARIO=="B4"|pareto$SCENARIO=="B4_FOR-"|pareto$SCENARIO=="B4_ISOS-"|pareto$SCENARIO=="B4_CRF-")

tmp_dat$SCENARIO<-as.factor(tmp_dat$SCENARIO)

#make the SCENARIOS as factors
pareto$SCENARIO<-as.factor(pareto$SCENARIO)
pareto$SCENARIO<-factor(pareto$SCENARIO, levels=c("B3","B3_FOR+","B3_CRF+","B3_ISOS+","B4_FOR-","B4_CRF-","B4_ISOS-","B4"))
scen_names<-levels(pareto$SCENARIO)

pareto$RESTRICTION<-as.factor(pareto$RESTRICTION)
pareto$RESTRICTION<-factor(pareto$RESTRICTION, levels=c("restrictive","relaxing"))
rel_names<-levels(pareto$RESTRICTION)

pareto$POLICY<-as.factor(pareto$POLICY)
pareto$POLICY<-factor(pareto$POLICY, levels=c("base","FOR","CRF","ISOS"))
pol_names<-levels(pareto$POLICY)

pareto$MODEL_RUN<-as.factor(pareto$MODEL_RUN)

```

# An overall statistical test to check the main tendencies of the differen runs
```{r}

summary(aov(N_WT~SCENARIO+MODEL_RUN,pareto))

tmp<-subset(pareto,pareto$SCENARIO=="B4")
summary(aov(CLUS~MODEL_RUN,tmp))
wilcox.test(tmp$CLUS ~ tmp$MODEL_RUN)
#graphical check
ggplot(tmp, aes(x=as.factor(MODEL_RUN), y=CLUS)) +   
    geom_boxplot()

```



```{r descriptives}

#descriptive table for appendix
desc<-as.data.frame(describeBy(pareto[,1:3],pareto$SCENARIO))

#Tabular form
desc_mw<-describeBy(x=pareto[3],group=pareto$SCENARIO, mat = T)
desc_WT<-describeBy(x=pareto[1],group=pareto$SCENARIO, mat = T)
desc_clus<-describeBy(x=pareto[2],group=pareto$SCENARIO, mat = T)
write.csv(desc_mw, paste("Y:/people/spreto/01_ETH/02_PUBLICATIONS/01_MAIN/3_WIND_OPTIM/Tables/",paste(cur_dat,"mw_desc.csv",sep="_"),sep=""))
write.csv(desc_WT, paste("Y:/people/spreto/01_ETH/02_PUBLICATIONS/01_MAIN/3_WIND_OPTIM/Tables/",paste(cur_dat,"WT_desc.csv",sep="_"),sep=""))
write.csv(desc_clus, paste("Y:/people/spreto/01_ETH/02_PUBLICATIONS/01_MAIN/3_WIND_OPTIM/Tables/",paste(cur_dat,"clus_desc.csv",sep="_"),sep=""))

#######Box plots to explore the data of the three goals for each scenario
clus<-ggplot(pareto, aes(x=as.factor(POLICY), y=CLUS, fill = POLICY)) +   
    geom_boxplot()+
    facet_wrap(~RESTRICTION)+
    #theme_light()+
    theme(legend.position = "none")+
    scale_fill_manual(values=c("#FF8000", "#00994D", "#0080ff","#ff33ff"))+
    labs(x ="POLICIES", y = "Clark-Evans ind. <--min")

n_WT<-ggplot(pareto, aes(x=as.factor(POLICY), y=N_WT, fill = POLICY)) +   
    geom_boxplot()+
    facet_wrap(~RESTRICTION)+
    #theme_light()+
    theme(legend.position = "none")+
    scale_fill_manual(values=c("#FF8000", "#00994D", "#0080ff","#ff33ff"))+
    labs(x ="POLICIES", y = "number of WT. <--min")+
    theme(axis.title.x = element_blank()) 
    
ener<-ggplot(pareto, aes(x=as.factor(POLICY), y=ENERDENS, fill = POLICY)) +   
    geom_boxplot()+
    facet_wrap(~RESTRICTION)+
    #theme_light()+
    theme(legend.position = "none")+
    scale_fill_manual(values=c("#FF8000", "#00994D", "#0080ff","#ff33ff"))+
    labs(x ="POLICIES", y = "Energy density [MWh/yha]. --> max")+
    theme(axis.title.x = element_blank())

plot_tmp<-ggarrange(ener, n_WT, clus,  ncol = 1,nrow = 3, common.legend = T,labels = "auto")    
jpeg(file=paste("D:/04_PROJECTS/2001_WIND_OPTIM/WIND_OPTIM_git/intermediate_steps/4_wp/descriptives/",paste(name,"_fitness_box.jpg",sep=""),sep=""),width = 1500, height = 2000)
plot(plot_tmp)
dev.off()


```



##statistics
```{r}
## 
my_comparisons <- list( c("B3", "B3_FOR+"),c("B3","B3_ISOS+"),c("B3","B3_CRF+"))
my_comparisons <- list( c("B4", "B4_FOR-"),c("B4","B4_ISOS-"),c("B4","B4_CRF-"))

#1. CHECK FOR NORMAL DISTR
tmp_dat %>%
  group_by(SCENARIO) %>%
  shapiro_test(N_WT)
#density plots per scen
ggplot(data=pareto, aes(x=ENERDENS, group=SCENARIO, fill=SCENARIO)) +
    geom_density(adjust=1.5)+ 
    facet_wrap(~SCENARIO) 
#homogeneity of variance
levene_test(tmp_dat,N_WT~SCENARIO,center = mean)

# if both not normal and inhomogeneity of variances == man whitney u test
#make comparison group manual
tmp_dat2<-subset(tmp_dat, tmp_dat$SCENARIO=="B3"|tmp_dat$SCENARIO=="B3_FOR+")

wilcox.test(tmp_dat2$N_WT ~ tmp_dat2$SCENARIO)

#if normal distributed but homogen variances == welch t.test
w<-welch.test(N_WT~SCENARIO,pareto)
paircomp(w)
#if both given == t.test
t.test(a$number_WT,b$number_WT,alternative = "two.sided", var.equal = FALSE)

```


## 2D scatter plot
```{r}

num<-c(1,2,3,4)
tmp_dat$num<-num[as.factor(tmp_dat$SCENARIO)]

A<-scatter2D(tmp_dat$N_WT, tmp_dat$CLUS,
          colvar = as.integer(tmp_dat$num),
          col = c("#FF8000", "#0080ff", "#00994D","#ff33ff"),
          xlab = "min<--N_WT",
          ylab ="min<--CLUSTER",
          cex=0.5, bty = "b2",
          colkey = list(at = c(1,2, 3, 4), side = 1, 
          addlines = TRUE, length = 0.5, width = 0.5,
          labels = c("B4", "B4_CRF-","B4_FOR-", "B4_ISOS-"))
          )
B<-scatter2D(tmp_dat$N_WT, tmp_dat$ENERDENS,
          colvar = as.integer(tmp_dat$num),
          col = c("#FF8000", "#0080ff", "#00994D","#ff33ff"),
          xlab = "min<--N_WT",
          ylab ="enerdens-->max",
          cex=0.5, bty = "b2",
          colkey = list(at = c(1,2, 3, 4), side = 1, 
          addlines = TRUE, length = 0.5, width = 0.5,
          labels = c("B4", "B4_CRF-","B4_FOR-", "B4_ISOS-"))
          )
C<-scatter2D(tmp_dat$CLUS, tmp_dat$ENERDENS,
          colvar = as.integer(tmp_dat$num),
          col = c("#FF8000", "#0080ff", "#00994D","#ff33ff"),
          xlab = "min<--CLUSTER",
          ylab ="enerdens-->max",
          cex=0.5, bty = "b2",
          colkey = list(at = c(1,2, 3, 4), side = 1, 
          addlines = TRUE, length = 0.5, width = 0.5,
          labels = c("B4", "B4_CRF-","B4_FOR-", "B4_ISOS-"))
          )
### relaxation

```


## 3D Pareto front
```{r}

scatter3d(tmp_dat$N_WT, tmp_dat$CLUS, tmp_dat$ENERDENS,
          xlab = "min<--N_WT",
          ylab ="min<--CLUSTER", 
          zlab = "max<--ENERDENSx",
          groups = tmp_dat$SCENARIO,
          surface = F,
          axis.scales = T,
          axis.ticks = T,
          ellipsoid = T,
          sphere.size = T)

# Add small dots on basal plane and on the depth plane
scatter3D_fancy <- function(x, y, z,..., colvar = colvar)
  {
   panelfirst <- function(pmat) {
      XY <- trans3D(x, y, z = rep(min(z), length(z)), pmat = pmat)
      scatter2D(XY$x, XY$y, col = "#999999", pch = ".", 
              cex = 0.1, add = TRUE, colkey = FALSE)
   
      XY <- trans3D(x = rep(min(x), length(x)), y, z, pmat = pmat)
      scatter2D(XY$x, XY$y, col = "#999999", pch = ".", 
              cex = 0.1, add = TRUE, colkey = FALSE)
  }
  scatter3D(x, y, z, ..., colvar = colvar, panel.first=panelfirst) 
}

scatter3D_fancy(tmp_dat$N_WT, tmp_dat$CLUS, tmp_dat$ENERDENS,
          colvar = as.integer(tmp_dat$num),
          col = c("#FF8000", "#0080ff", "#00994D","#ff33ff"),
          xlab = "min<--N_WT",
          ylab ="min<--CLUSTER", 
          zlab = "max<--ENERDENS",
          theta = 25,d = 1, phi = 0, cex=0.3, bty = "b2",ticktype = "detailed",colkey = list(at = c(1,2, 3, 4), side = 1, 
          addlines = TRUE, length = 0.5, width = 0.5,
          labels = c("B4", "B4_CRF-","B4_FOR-", "B4_ISOS-")))
              
```


## some maps

You can also embed plots, for example:

```{r pressure, echo=FALSE}
conn <- dbConnect(Postgres(), dbname = "publication_3_fin", host = "localhost", port = 5432, 
                      user = "postgres", password = "reto89LLSIMI")

scen_names<-dbGetQuery(conn,"SELECT table_name FROM information_schema.tables WHERE table_schema='optim_res_201005'")
bound<-st_read(dsn= conn, Id(schema="GEO_base_data", table = "CH_boundaries"))
bound<-st_transform(bound,crs = "+init=epsg:21781") 

###localhost
B3<-st_read("Y:/people/spreto/2001_WIND_OPTIM/spat_pts_201204/B3_A.shp")
bound<-st_read("Y:/people/spreto/2001_WIND_OPTIM/in/CH_Grenze.shp")
LT<-st_read("Y:/people/spreto/2001_WIND_OPTIM/in/LT3.shp")
bound<-st_transform(bound,crs = "+init=epsg:21781") 


## important robust B3
B3<-B3[order(-B3$par_rob),]
sum_prod = 0
ind=0

for(i in 1:nrow(B3)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-B3$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
rob_B3<-B3[1:i,]
ppptmp<-as.ppp(rob_B3)

mean(nndist(ppptmp))

#compute the spatial distribution of robust solution with CE index
#convert the pts in ppp and the polygon into owin in order to compute clark evans

b<-as(st_zm(bound), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
clarkevans(ppptmp, clipregion =  p)

mean(rob_B3$ALTI)
mean(rob_B3$DIST_HZ)
mean(rob_B3$weigh_stre)


###Alps
b<-as(st_zm(LT[2]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_B3,rob_B3$LT==2)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)


#PRELAPS JURA
b<-as(st_zm(LT[3]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_B3,rob_B3$LT==3)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)

### PLATEAU
b<-as(st_zm(LT[1]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_B3,rob_B3$LT==1)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)


### plot theses imp Baseline pts
map_tmp<-ggplot(data = bound) +
    geom_sf() +
    geom_density_2d_filled(mapping = aes(x=st_coordinates(rob_B3)[,1] ,y=st_coordinates(rob_B3)[,2]), data=rob_B3,
                     alpha=0.5,contour_var = "ndensity",colour=F)+
    geom_sf(data = bound, fill = NA, color = "gray")+
    geom_sf(data = rob_B3, color= "black", size=0.8)

### and here the same for the others (adjust accordingly)
tmp<-st_read("Y:/people/spreto/2001_WIND_OPTIM/spat_pts_201204/B3_ISOS+.shp")
## important robust B3
tmp<-tmp[order(-tmp$par_rob),]
sum_prod = 0
ind=0

for(i in 1:nrow(tmp)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-tmp$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
rob_tmp<-tmp[1:i,]


#compute the spatial distribution of robust solution with CE index
#convert the pts in ppp and the polygon into owin in order to compute clark evans
ppptmp<-as.ppp(rob_tmp)
mean(nndist(ppptmp))
mean(rob_tmp$DIST_HZ)
mean(rob_tmp$ALTI)
mean(rob_tmp$weigh_stre)

clarkevans(ppptmp, clipregion =  p)

#here we can plot the 30 nearest neighbors and their average distances
ANN <- apply(nndist(ppptmp, k=1:30),2,FUN=mean)
plot(ANN ~ eval(1:30), type="b", main=NULL, las=1)


###Alps
b<-as(st_zm(LT[2]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_tmp,rob_tmp$LT==2)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)


#PRELAPS JURA
b<-as(st_zm(LT[3]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_tmp,rob_tmp$LT==3)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)

### PLATEAU
b<-as(st_zm(LT[1]), "Spatial")
y <- as(b, "SpatialPolygons")
LT_owin <- as.owin(y)
#subset pts
alpB3<-subset(rob_tmp,rob_tmp$LT==1)
ppptmp<-as.ppp(alpB3)
clarkevans(ppptmp, clipregion =  LT_owin)


#BARPLOT for LT distribution from csv
LT_WT<-read.csv("Y:/people/spreto/2001_WIND_OPTIM/LT_WT_201207.csv", sep=";")
ggbarplot(LT_WT, x= "POLICY", y= "N_WT", color = "LANDSCAPE_TYPE",
  fill = "LANDSCAPE_TYPE", palette = c( "#808000","#808080", "#008080"))+
    facet_wrap(~RESTRICTION)+
  theme_gray()

### plot theses imp Baseline pts
map_tmp<-ggplot(data = bound) +
    geom_sf() +
    geom_density_2d_filled(mapping = aes(x=st_coordinates(rob_tmp)[,1] ,y=st_coordinates(rob_tmp)[,2]), data=rob_tmp,
                     alpha=0.5,contour_var = "ndensity",colour=F)+
    geom_sf(data = bound, fill = NA, color = "gray")+
    geom_sf(data = rob_tmp, color= "black", size=0.8)

#distribution in LT's
hist(rob_tmp$LT)

#merge the two pts to compare
joined<-st_join(B3, B3CRF)
joined<-joined[,-c(40:78)]
names(joined)[names(joined) == "par_rob.y"] <- "rob_parCRF"
joined[c("rob_parCRF")][is.na(joined[c("rob_parCRF")])] <- 0

#we calculate the difference between the "security" of wind turbines of B3 and B4
joined$delta_rob<-(joined$par_rob.x-joined$rob_parCRF)

#order the data with descending par_rob of baseline scenario
joined<-joined[order(-joined$par_rob.x),]

#while loop to sum prod MW until 4300000 MWh/y is reached
sum_prod = 0
ind=0

for(i in 1:nrow(joined)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-joined$prod_MW.x[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
tmpA<-joined[1:i,]

ggplot(data = tmpA) +
  #geom_sf(data = tmpA, color=tmpA$delta_rob)+
  geom_sf(mapping=aes(x=st_coordinates(tmpA)[,1] ,y=st_coordinates(tmpA)[,2], color=delta_rob))+
  scale_colour_continuous(type = "viridis")+
    geom_sf(data = bound, fill = NA, color = "gray")


#large negative values indicate that the WT becomes more important when restricting the policy. High positive values indicate that a WT is not important in the restricted scenario but in the base line
mapview::mapview(tmpA,zcol="delta_rob")


```

## Wind CH optimization first draft results
In order to discuss the content of the paper I show the first insights in the optimization analysis. Before I do this, here are a few points to consider / to konw in order to interpret the data
1) All the optimizations have been performed with three goals: a) minimum amount of wind turbines [integer], b) maximum amount of clustering [--> smaller CE_index=max clustering] and c) maximizing the energy density [MWH/yHA].

2) We used 20'000 iterations and a mutation probability of .2 in most cases, after visual inspection of HV-curves we used 50'000 iterations and mut prob =.6 for three scenarios.

3) SO far we calculated 16 scenarios. 4 "base line" scenarios ==> B1: "Build wind turbines where ever you want (despite the physical and strong leagal constraints)", B2: "Not possible to build WT in Ausschlussgebieten", B3: "Not possible to build WT in Ausschluss + Vorbehaltsgebiet", B4: "Not possible to build WT in any Bundesinteressen"

4) We then investigated the effects of forest (FOR), crop rotation farming (FFF) and national landscap heritage zones (BLN) --> we call this group in the data frame. Thus each final scenario is a composition of a basline scenario and a specific group, which can be more restrictive (+) or facilitate a group for the siting of WT's  (-). E.g. B1_FOR+ --> "possible to build WT everywhere, except in forests --> forests are more protected"
or B4_FOR- "Not possible to build WT in any Bundesinteressen, but within forests, forests are less protected" (since forests are of further national interests)


# Basic fitness data
For each scenario (N=16), 20'000 times a set of 80 combinations (individuals) of "optimal" wind turbine locations are calculated and stored (updated) in the pareto front. In the last run, we expect that the set of 80 individuals represent an optimal solution which are not dominated (better) by other possible siting strategies. In the following chunk we read in the the values (number of WT, cluster index and energy_density for each individual (80) of each Scenario == 1280 observations)

##First question
"What is the effect on (n_WT, clustering, energy density) between the four national frame policies (B3,B4)?"


```{r}


## CE
#1. CHECK FOR NORMAL DISTR
all %>%
  group_by(SCENARIO) %>%
  shapiro_test(CE_index)

levene_test(all,CE_index~SCENARIO,center = mean) #homogeneity of variance

#graphical check
clus<-ggboxplot(all, x = "SCENARIO", y = "CE_index", 
        ylab = "CE_ind", xlab = "SCENARIO")+
   stat_compare_means(comparisons = my_comparisons, label = "p.signif",
                     ref.group = "B3", method="t.test" )+
  stat_compare_means(label.y = .5, method = "anova")

anov<-aov(CE_index~SCENARIO,data=all)
summary(anov)
TukeyHSD(anov,"SCENARIO")


## enerdens
#1. CHECK FOR NORMAL DISTR
all %>%
  group_by(SCENARIO) %>%
  shapiro_test(mean_MWH.yHA)

levene_test(all,mean_MWH.yHA~SCENARIO,center = mean) #homogeneity of variance is given

#since homogeneity of variance is not given and we have violations of normality, we perform a Welch-Test
#if levene p<.05 thus a welch test should be performed, since variances are not homogen
compare_means(mean_MWH.yHA~SCENARIO,all)



#graphical check
enerdens<-ggboxplot(all, x = "SCENARIO", y = "mean_MWH.yHA", 
        ylab = "mean_MWH.yHA", xlab = "SCENARIO")+
   stat_compare_means(comparisons = my_comparisons, label = "p.signif",
                     ref.group = "B3" )+
  stat_compare_means(label.y = 1.1)

plot_tmp<-ggarrange(num_WT, clus, enerdens,  ncol = 1,nrow = 3, labels = "auto")


jpeg(file=paste("D:/04_PROJECTS/2001_WIND_OPTIM/WIND_OPTIM_git/intermediate_steps/3_wp/OPTIM_RES/results_stat/Q1/",paste(cur_dat,"all.jpg",sep="_"),sep=""),width = 1500, height = 1000)
plot(plot_tmp)
dev.off()

## B4 is different from all other, B1,B2,B3 have equal energy densities

```

## security analysis I
Which wind turbines in restricted areas (FOR, FFF or ISOS) are of interest in order to support the overall optimized allocation goal?
```{r}
conn <- dbConnect(Postgres(), dbname = "publication_3_fin", host = "localhost", port = 5432, 
                      user = "postgres", password = "reto89LLSIMI")

pts_B3<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B3_2020-10-08_res"))
pts_B4<-st_read(dsn = conn, Id(schema="optim_res_201005", table = "B4_2020-10-10_res"))

##and for B4 scenario
tmpB<-B_join[with(B_join, order(B_join$sum_popPAR_B4,decreasing = T)), ]

#while loop to sum prod MW until 4300000 MWh/y is reached
sum_prod = 0
ind=0

for(i in 1:nrow(tmpB)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-tmpB$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}

#create a subset to map  
tmpB<-tmpB[1:i,]
mapview::mapview(tmpB,zcol="sum_popPAR_B4")

# where are the common secure points and how much energy do they produce
both<-rbind(tmpA,tmpB)
both<-both[duplicated(both$WT_ID), ]
sum(both$prod_MW.x)
mapview::mapview(both,zcol="delt_B3_B4")


#what are the differences?
mapview::mapview(subset(B_join,B_join$delt_B3_B4>10|B_join$delt_B3_B4<10*-1),zcol="delt_B3_B4")


#subset the joined df and analyse only the points which are in FOR,FF,ISOS
in_restr<-subset(B_join,B_join$DIST_FOR.x<1 | B_join$FFF.x==1 | B_join$DIST_ISOS.x<1000)
#map these points
mapview::mapview(subset(in_restr,in_restr$delt_B3_B4>1),zcol="delt_B3_B4")

#0= WT is in a FFF or FOR or ISOS but the WT was not very interesting in B3. 80= WT is in FFF or FOr, or ISOS and it contributes to an optimal B3 solution.

```



##costs
```{r}
###localhost
B3<-st_read("Y:/people/spreto/2001_WIND_OPTIM/spat_pts_201204/B4_FFF-.shp")

## important robust
B3<-B3[order(-B3$par_rob),]
sum_prod = 0
ind=0

for(i in 1:nrow(B3)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-B3$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
rob_B3<-B3[1:i,]

rob_tmp<-rob_B3

tmp_sub<-subset(rob_tmp,rob_tmp$FFF==1 & rob_tmp$DIST_FOR>1 & rob_tmp$DIST_ISOS>1000)
print(nrow(tmp_sub))

#import the relative deltas 
rel_delt<-read.csv("Y:/people/spreto/2001_WIND_OPTIM/delta_rel_201208.csv",sep=";")

#plot pos neg bar
ggplot(data = rel_delt,
       aes(x = REL_DIFF, y = WT_in_restr,
           fill = REL_DIFF > 0))+
  geom_bar(stat = "identity")+
  facet_wrap(~SCENARIO)+
  labs(y="Areas for Allocating WT", x = "Relative change compared to baseline Scenario [%]")+
  theme(axis.title = element_text(size =16), axis.text = element_text(size=10))+
  scale_fill_manual(values=c( "#31913e","#eb4034"))+
  coord_flip()

```


```{r}
## uncertainty mapping of optimal solutions
### and here the same for the others (adjust accordingly)
tmp<-st_read("Y:/people/spreto/2001_WIND_OPTIM/spat_pts_201204/B3_A.shp")

## important robust B3
tmp<-tmp[order(-tmp$par_rob),]
sum_prod = 0
ind=0

for(i in 1:nrow(tmp)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-tmp$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
rob_tmp<-tmp[1:i,]
rob_tmp<-subset(rob_tmp, rob_tmp$FFF==1)

 

map_sec<-ggplot(rob_tmp) +
    geom_sf(data = bound, fill = NA, color = "gray", size=.8)+
    geom_sf(data = rob_tmp, aes(color= par_rob), show.legend = "point", size=.8)+
    theme_light()+
  scale_color_gradient(low="blue", high="red")+
   theme(axis.text=element_text(size=10))

tmpB<-st_read("Y:/people/spreto/2001_WIND_OPTIM/spat_pts_201204/B4.shp")
tmpB<-tmpB[order(-tmpB$par_rob),]
sum_prod = 0
ind=0

for(i in 1:nrow(tmpB)){
 if(sum_prod>4300000){
   break
   print(i)
  }
  tmp_prod<-tmpB$prod_MW[i]
  sum_prod<-sum_prod+tmp_prod
}
#create a subset to map  
rob_tmpB<-tmpB[1:i,]

##common important robust pts of B4 and B3
both<-rbind(rob_tmp,rob_tmpB)
both<-both[duplicated(both$WT_ID), ]
ggplot(both) +
    geom_sf(data = bound, fill = NA, color = "gray", size=.8)+
    geom_sf(data = both, aes(color= prod_MW), show.legend = "point", size=1)+
    theme_light()

sum(both$prod_MW)

```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r}
in_dat %>%
  group_by(SCENARIO) %>%
  summarise_at(vars(number_WT,CE_index,mean_MWH.yHA), funs(mean(., na.rm=TRUE)))

#read the last calc
cen<-st_read(dsn = conn, Id(schema="optim_res_201005", table = as.character(scen_names[4,])))


tmp<-subset(cen,cen$FFF==1&cen$clus_max==1)

B3_opt<-st_read("D:/04_PROJECTS/2001_WIND_OPTIM/WIND_OPTIM_git/optim_res/B3_201008.shp")
B3_opt<-st_drop_geometry(B3_opt)
B3_opt_WT <- subset(B3_opt,B3_opt$amount_min==1)
res3<-B3_opt_WT%>%group_by(CANT_name)%>%summarise_at(vars(prod_MW_ne),funs(sum(.,na.rm = F)/1000))

write.csv(res3,"D:/04_PROJECTS/2001_WIND_OPTIM/WIND_OPTIM_git/optim_res/B3_nWT.csv")

```

